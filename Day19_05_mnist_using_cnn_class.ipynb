{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day19_05_mnist_using_cnn_class.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DionKimmm/2019SummerML/blob/master/Day19_05_mnist_using_cnn_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCYrUXLmkppg",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Network Class를 이용한 MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq4L8PyW0cFr",
        "colab_type": "text"
      },
      "source": [
        "#MNIST 손글씨 인식하기\n",
        "* 미국 국립표준기술원(NIST)에서 고등학생과 인구조사국 직원 등이 쓴 손글씨를 수집하여 만든 70,000개의 숫자 손글씨 데이터셋\n",
        "\n",
        "![대체 텍스트](https://snowdeer.github.io/assets/machine-learning/024.png)\n",
        "\n",
        "* 총 70000개의 데이터 \n",
        "* 학습용데이터 60000\n",
        "* 테스트용 데이터 10000\n",
        "* 손글씨 한 장의 이미지는 28 x 28 = 784개의 픽셀로 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b462dWoPYIQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsKaBcgJYKeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY0iZc1KYO2G",
        "colab_type": "code",
        "outputId": "08cf2bc9-d7e2-4b8d-eccf-c1d6db000e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0722 06:54:38.642047 140193927972736 deprecation.py:323] From <ipython-input-3-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0722 06:54:38.643852 140193927972736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0722 06:54:38.645793 140193927972736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0722 06:54:38.937980 140193927972736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0722 06:54:38.942141 140193927972736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0722 06:54:39.000531 140193927972736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVdnmo3cYQp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyper parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vn0_70tdUpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "\n",
        "    def __init__(self, sess, name):\n",
        "        self.sess = sess\n",
        "        self.name = name\n",
        "        self._build_net()\n",
        "\n",
        "    def _build_net(self):\n",
        "        with tf.variable_scope(self.name):\n",
        "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
        "            # for testing\n",
        "            self.keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "            # input place holders\n",
        "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
        "            # img 28x28x1 (black/white)\n",
        "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
        "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "            # L1 ImgIn shape=(?, 28, 28, 1)\n",
        "            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "            #    Conv     -> (?, 28, 28, 32)\n",
        "            #    Pool     -> (?, 14, 14, 32)\n",
        "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L1 = tf.nn.relu(L1)\n",
        "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
        "                                strides=[1, 2, 2, 1], padding='SAME')\n",
        "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
        "            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
        "            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
        "            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
        "            '''\n",
        "\n",
        "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
        "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "            #    Conv      ->(?, 14, 14, 64)\n",
        "            #    Pool      ->(?, 7, 7, 64)\n",
        "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L2 = tf.nn.relu(L2)\n",
        "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
        "                                strides=[1, 2, 2, 1], padding='SAME')\n",
        "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
        "            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
        "            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
        "            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
        "            '''\n",
        "\n",
        "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
        "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
        "            #    Conv      ->(?, 7, 7, 128)\n",
        "            #    Pool      ->(?, 4, 4, 128)\n",
        "            #    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
        "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            L3 = tf.nn.relu(L3)\n",
        "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
        "                                1, 2, 2, 1], padding='SAME')\n",
        "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
        "\n",
        "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
        "            '''\n",
        "            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
        "            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
        "            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
        "            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
        "            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
        "            '''\n",
        "\n",
        "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
        "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
        "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
        "            b4 = tf.Variable(tf.random_normal([625]))\n",
        "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
        "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
        "            '''\n",
        "            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
        "            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
        "            '''\n",
        "\n",
        "            # L5 Final FC 625 inputs -> 10 outputs\n",
        "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
        "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
        "            b5 = tf.Variable(tf.random_normal([10]))\n",
        "            self.logits = tf.matmul(L4, W5) + b5\n",
        "            '''\n",
        "            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
        "            '''\n",
        "\n",
        "        # define cost/loss & optimizer\n",
        "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=self.logits, labels=self.Y))\n",
        "        self.optimizer = tf.train.AdamOptimizer(\n",
        "            learning_rate=learning_rate).minimize(self.cost)\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
        "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    def predict(self, x_test, keep_prop=1.0):\n",
        "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
        "\n",
        "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
        "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
        "\n",
        "    def train(self, x_data, y_data, keep_prop=0.7):\n",
        "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
        "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddtPBRE1YWWL",
        "colab_type": "code",
        "outputId": "1fbb21c9-9173-4d64-817a-e6037409130f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "\n",
        "\n",
        "# initialize\n",
        "sess = tf.Session()\n",
        "m1 = Model(sess, \"m1\")\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0722 06:54:39.509083 140193927972736 deprecation.py:506] From <ipython-input-5-dec618978d11>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0722 06:54:39.619359 140193927972736 deprecation.py:323] From <ipython-input-5-dec618978d11>:94: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEsz-d7udXNu",
        "colab_type": "code",
        "outputId": "04ff0dbc-096c-4aff-830d-2abe8ee05da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "print('Learning Started!')\n",
        "\n",
        "# train my model\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        c, _ = m1.train(batch_xs, batch_ys)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning Finished!')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning Started!\n",
            "Epoch: 0001 cost = 0.368709098\n",
            "Epoch: 0002 cost = 0.093371111\n",
            "Epoch: 0003 cost = 0.071228620\n",
            "Epoch: 0004 cost = 0.056813984\n",
            "Epoch: 0005 cost = 0.049435653\n",
            "Epoch: 0006 cost = 0.045391965\n",
            "Epoch: 0007 cost = 0.040557530\n",
            "Epoch: 0008 cost = 0.039365858\n",
            "Epoch: 0009 cost = 0.037672801\n",
            "Epoch: 0010 cost = 0.032882162\n",
            "Epoch: 0011 cost = 0.031097731\n",
            "Epoch: 0012 cost = 0.030819789\n",
            "Epoch: 0013 cost = 0.027237054\n",
            "Epoch: 0014 cost = 0.024719113\n",
            "Epoch: 0015 cost = 0.026572880\n",
            "Learning Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBoIvj3HdXti",
        "colab_type": "code",
        "outputId": "d36db57e-9202-408e-eed6-45cc2ddc475a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Test model and check accuracy\n",
        "print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24Yi-W-cdZGJ",
        "colab_type": "code",
        "outputId": "86b3daa2-c198-40c0-b9ec-20c5552cc16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Get one and predict\n",
        "r = random.randint(0, mnist.test.num_examples - 1)\n",
        "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
        "print(\"Prediction: \", sess.run(\n",
        "    tf.argmax(m1.logits, 1), feed_dict={m1.X: mnist.test.images[r:r + 1], m1.keep_prob: 1}))\n",
        "\n",
        "plt.imshow(mnist.test.images[r:r + 1].\n",
        "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  [9]\n",
            "Prediction:  [9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSDoI0PxeEyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}