{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day24_03_Various_optimizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DionKimmm/2019SummerML/blob/master/Day24_03_Various_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqU9-NS3kEtV",
        "colab_type": "text"
      },
      "source": [
        "# 다양한 Optimizer의 사용 실습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgVDsvPCBUdt",
        "colab_type": "text"
      },
      "source": [
        "#Optimizer\n",
        "* train(학습)의 목표 : Loss Function의 값을 최소로, 가능한 빨리 하기.\n",
        "* AdamOptimizer를 일반적으로 사용합니다. \n",
        "* SGD(확률적 경사 하강법), Momentum, AdaGrad, Adam. 4개 중 모든 문제에서 항상 뛰어난 기법은 없습니다. 각자의 장단점이 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTTPOCr5C9q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y195cUTICn1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "tf.set_random_seed(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unoho7yfC1I6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyEJvWH2C2uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKQqT1c3C_fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf8ERxb_DDts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
        "b1 = tf.Variable(tf.random_normal([256]))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDLdzzGoEfU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
        "b2 = tf.Variable(tf.random_normal([256]))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyfzV8VSEgBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
        "b3 = tf.Variable(tf.random_normal([10]))\n",
        "hypothesis = tf.matmul(L2, W3) + b3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24JUrPxjEv5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define cost/loss & optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=hypothesis, labels=Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\\\n",
        "#                                        momentum = 0.03).minimize(cost)\n",
        "\n",
        "# optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv1Ri-iSEyd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LofsIkrSE0dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train my model\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
        "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
        "        avg_cost += c / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning Finished!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM3X24JdE2r9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test model and check accuracy\n",
        "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
        "      X: mnist.test.images, Y: mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47duf_PBE3el",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get one and predict\n",
        "r = random.randint(0, mnist.test.num_examples - 1)\n",
        "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
        "print(\"Prediction: \", sess.run(\n",
        "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}